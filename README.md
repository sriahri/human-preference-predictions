# Human Preference Predictions
This project  predicts which responses users will prefer in a head-to-head battle between chatbots powered by large language models (LLMs). 
## Introduction
This project focuses on building a machine learning model that accurately predicts user preferences between responses generated by two different Large Language Models (LLMs). Drawing from a dataset of user choices collected from Chatbot Arena, we aim to develop a preference prediction model that addresses the limitations of directly prompting LLMs for such judgments, including biases towards position, verbosity, and self-promotion. By successfully predicting user preferences, this research contributes significantly to the development of more user-friendly and effective LLM-powered conversational systems that can better adapt to individual user needs and expectations. This research will contribute to the development of LLMs that can better tailor responses to individual user preferences, leading to more user-friendly and widely accepted AI-powered conversation systems. This aligns with the concept of "reward models" or "preference models" crucial for Reinforcement Learning from Human Feedback (RLHF).

## Dataset
The dataset consists of user interactions from the ChatBot Arena. In each user interaction a judge provides one or more prompts to two different large language models, and then indicates which of the models gave the more satisfactory response. The dataset can be found at [dataset](https://drive.google.com/file/d/1VKlPDHf_WAaqEs3eNtjY2ZfWy5zmQjhs/view?usp=drive_link.)

## Exploratory Data Analysis
The exploratory data analysis (EDA) is performed on a dataset of LLM comparisons from Chatbot Arena. It begins by loading the dataset and examining its structure. Then, it analyzes the distribution of models used in the comparisons, identifies the most frequently compared model pairs, and calculates the win rates for each model. The code visualizes these findings using bar charts created with Plotly, showcasing the distribution of model usage, the most frequent model comparisons, and the top- and bottom-rated models based on their win rates. Finally, the code extracts and prepares the losing and winning responses from the dataset for further analysis, such as sentiment analysis or topic modeling. This EDA provides valuable insights into the dataset and informs subsequent steps in the analysis and model development process. It is present in the [EDA Code](EDA_Code.ipynb)

## Using Roberta
This approach implements a machine learning model for predicting user preferences between responses generated by different Large Language Models (LLMs). It begins by loading and preprocessing the training and test datasets, concatenating prompts with responses and creating balanced datasets. Next, it utilizes the pre-trained RoBERTa model from the transformers library, fine-tuning it for the task of preference prediction. The code employs techniques like data splitting, tokenization, and creating PyTorch datasets and DataLoaders for efficient training. The training process includes a loop over epochs, where the model is trained on the training data, evaluated on the validation set, and the best model is saved based on validation performance. To improve model robustness, 5-fold cross-validation is implemented, and the average validation score is calculated. Finally, the trained model is used to make predictions on the test data, and the results are formatted and saved in the submission.csv file. The code is present at [Basic code](Code_Basic.ipynb)

## Using Llama
This approach demonstrates the inference process for a multi-GPU inference setup, utilizing the Llama 2 8b-chat model fine-tuned with PEFT (Parameter-Efficient Fine-Tuning) for a chatbot arena task. The code begins by importing necessary libraries and loading the test dataset. It then preprocesses the text data by combining prompt, response A, and response B into a single input string. Subsequently, the input text is tokenized using the provided tokenizer, and the resulting token IDs and attention masks are stored in a DataFrame. Two LlamaForSequenceClassification models are loaded onto separate GPUs, each with a corresponding PEFT configuration for efficient fine-tuning. The code then defines an inference function that processes data in batches, performs inference with the specified model and device, and returns the predicted probabilities for each class (winner_model_a, winner_model_b, winner_tie). To leverage the multi-GPU setup, the test dataset is split into two halves, and two threads are spawned to execute inference concurrently on each GPU. Finally, the predicted probabilities are combined, assigned to the submission DataFrame, and saved to the submission.csv file. This approach effectively utilizes multiple GPUs to accelerate the inference process, making it suitable for large-scale inference tasks. The code is available at [Llama](FineTuned_Llama_model.ipynb)

### Key points:

Multi-GPU Inference: The code leverages two GPUs to parallelize the inference process, significantly improving performance.
PEFT (Parameter-Efficient Fine-Tuning): The model is fine-tuned using PEFT, which allows for efficient training and inference by only updating a small subset of parameters.
8-bit Quantization: 8-bit quantization is employed using the BitsAndBytesConfig to reduce memory consumption and accelerate inference.
Efficient Memory Management: Techniques like torch.cuda.empty_cache() are used to free up GPU memory between batches, further optimizing performance.

## Using Gemma
This approach performs inference for a chatbot arena task using a fine-tuned Gemma2 model on a multi-GPU setup. It starts by installing necessary libraries and loading the test dataset. The code then preprocesses the input data by combining prompts, response A, and response B into a single input string. Subsequently, it tokenizes the input text using the GemmaTokenizerFast and creates DataFrames for the original and augmented (with swapped responses) data. Two Gemma2ForSequenceClassification models are loaded onto separate GPUs, each loaded with the corresponding PEFT weights for fine-tuning. An inference function is defined to efficiently process data in batches, utilizing GPU acceleration and mixed precision (autocast) for improved performance. The code then leverages a ThreadPoolExecutor to parallelize inference across the two GPUs, significantly speeding up the process. Optionally, test-time augmentation (TTA) is implemented by swapping responses and performing inference again. Finally, the predicted probabilities from the model are averaged (if TTA is enabled) and stored in the submission DataFrame, which is then saved to the submission.csv file. This approach demonstrates effective utilization of multiple GPUs and optimization techniques for efficient and accurate inference on the chatbot arena task. The code is available at [Gemma](FineTuned_Gemma_model.ipynb)

## Evaluation and Results
This project evaluates the performance of various fine-tuned language models, including Roberta, Llama, and Gemma, on the Chatbot Arena dataset. The primary goal was to predict user preferences between responses generated by different LLMs. Experiments were conducted to assess the suitability of different models, with the Gemma model consistently demonstrating superior performance, achieving the lowest cross-entropy loss. This highlights its ability to effectively capture subtle nuances in language and predict user preferences accurately.

### Evaluation Methodology:

Model performance was evaluated using cross-entropy loss:

Loss = - (y * log(p) + (1 - y) * log(1 - p))

where:

y is the true label (0 or 1) and
p is the predicted probability

### Results:

Gemma Model Excellence: The Gemma model achieved the lowest cross-entropy loss of 1.02547, demonstrating superior performance compared to Roberta (1.53425) and Llama (1.16277).
Efficiency Gains: The Gemma model exhibited significant efficiency gains, achieving high accuracy with fewer training epochs and faster inference times. For instance, inference time for Gemma was approximately 3 seconds, compared to 5 seconds for Llama and 4 minutes 12 seconds for Roberta.
PEFT Efficiency: The use of PEFT (Parameter-Efficient Fine-Tuning) significantly improved the training and inference speed of the Llama model, demonstrating its effectiveness in reducing computational overhead.
These results demonstrate the effectiveness of the Gemma model for this task, showcasing its potential for real-world applications in chatbot and conversational AI systems.

## References
Refer to reference section at [here](Final_Project_Report_NLP_GenAI.pdf)
